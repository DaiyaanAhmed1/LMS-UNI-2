// AI Service for Sage AI Integration
// Simple, deployment-friendly AI integration with rate limiting

class AIService {
  constructor() {
    this.openaiKey = import.meta.env.VITE_OPENAI_API_KEY || '';
    this.geminiKey = import.meta.env.VITE_GEMINI_API_KEY || '';
    this.deepseekKey = import.meta.env.VITE_DEEPSEEK_API_KEY || '';
    this.useGemini = import.meta.env.VITE_USE_GEMINI === 'true';
    this.useDeepSeek = import.meta.env.VITE_USE_DEEPSEEK === 'true';
    
    console.log('üîß AI Service Configuration:');
    console.log('  - OpenAI Key length:', this.openaiKey.length);
    console.log('  - Gemini Key length:', this.geminiKey.length);
    console.log('  - DeepSeek Key length:', this.deepseekKey.length);
    console.log('  - Use Gemini:', this.useGemini);
    console.log('  - Use DeepSeek:', this.useDeepSeek);
    
    this.openaiURL = 'https://api.openai.com/v1/chat/completions';
    this.geminiURL = 'https://generativelanguage.googleapis.com/v1/models/gemini-1.5-flash:generateContent';
    this.deepseekURL = 'https://openrouter.ai/api/v1/chat/completions';
    

    
    this.rateLimit = {
      free: { requests: 200, window: 3600000 }, // 200 requests per hour for testing
      pro: { requests: 1000, window: 3600000 } // 1000 requests per hour
    };
    
    // Sage AI specific limits
    this.sageAILimits = {
      free: 20, // 20 free Sage AI chats
      pro: 1000 // Unlimited for PRO
    };
    this.userRequests = new Map(); // Track user requests
    this.sageAIRequests = new Map(); // Track Sage AI specific requests
    
    // Initialize Sage AI requests from localStorage
    this.initializeSageAIFromStorage();
  }

  // Check if user has exceeded rate limit
  checkRateLimit(userId, userType = 'free') {
    const now = Date.now();
    const limit = this.rateLimit[userType];
    
    if (!this.userRequests.has(userId)) {
      this.userRequests.set(userId, []);
    }
    
    const userRequests = this.userRequests.get(userId);
    const recentRequests = userRequests.filter(time => now - time < limit.window);
    
    if (recentRequests.length >= limit.requests) {
      return false; // Rate limit exceeded
    }
    
    // Add current request
    recentRequests.push(now);
    this.userRequests.set(userId, recentRequests);
    return true;
  }



  // Get remaining messages for user (without consuming)
  getRemainingMessages(userId, userType = 'free') {
    const now = Date.now();
    const limit = this.rateLimit[userType];
    
    if (!this.userRequests.has(userId)) {
      return limit.requests;
    }
    
    const userRequests = this.userRequests.get(userId);
    const recentRequests = userRequests.filter(time => now - time < limit.window);
    
    return Math.max(0, limit.requests - recentRequests.length);
  }

  // Initialize Sage AI requests from localStorage
  initializeSageAIFromStorage() {
    try {
      const stored = localStorage.getItem('sageAIRequests');
      if (stored) {
        const parsed = JSON.parse(stored);
        this.sageAIRequests = new Map(Object.entries(parsed));
        console.log('üì± Loaded Sage AI requests from localStorage:', parsed);
      }
    } catch (error) {
      console.warn('‚ö†Ô∏è Failed to load Sage AI requests from localStorage:', error);
    }
  }

  // Save Sage AI requests to localStorage
  saveSageAIToStorage() {
    try {
      const data = Object.fromEntries(this.sageAIRequests);
      localStorage.setItem('sageAIRequests', JSON.stringify(data));
      console.log('üíæ Saved Sage AI requests to localStorage:', data);
    } catch (error) {
      console.warn('‚ö†Ô∏è Failed to save Sage AI requests to localStorage:', error);
    }
  }

  // Check Sage AI specific limit
  checkSageAILimit(userId, userType = 'free') {
    const limit = this.sageAILimits[userType];
    
    if (!this.sageAIRequests.has(userId)) {
      this.sageAIRequests.set(userId, 0);
    }
    
    const usedRequests = this.sageAIRequests.get(userId);
    
    console.log(`üîç Sage AI limit check: ${usedRequests}/${limit} for user ${userId}`);
    
    if (usedRequests >= limit) {
      console.log(`üö´ Sage AI limit exceeded: ${usedRequests}/${limit}`);
      return false;
    }
    
    // Increment usage
    this.sageAIRequests.set(userId, usedRequests + 1);
    
    // Save to localStorage after incrementing
    this.saveSageAIToStorage();
    
    console.log(`‚úÖ Sage AI request allowed: ${usedRequests + 1}/${limit}`);
    return true;
  }

  // Get remaining Sage AI messages
  getRemainingSageAIMessages(userId, userType = 'free') {
    const limit = this.sageAILimits[userType];
    
    if (!this.sageAIRequests.has(userId)) {
      return limit;
    }
    
    const usedRequests = this.sageAIRequests.get(userId);
    return Math.max(0, limit - usedRequests);
  }



  // Get AI response with fallback
  async getAIResponse(message, userId, userType = 'free', language = 'en', isSageAI = false) {
    console.log('üöÄ getAIResponse called with:', {
      message: message.substring(0, 50) + '...',
      userId,
      userType,
      language,
      isSageAI
    });
    
    try {
      // Check Sage AI specific limit if this is a Sage AI request
      if (isSageAI && !this.checkSageAILimit(userId, userType)) {
        console.log('Sage AI limit exceeded, showing PRO upgrade message');
        return this.getProUpgradeMessage(userType, language, 'sage_ai_limit');
      }
      
      // Check overall rate limit
      if (!this.checkRateLimit(userId, userType)) {
        console.log('Rate limit exceeded, showing PRO upgrade message');
        return this.getProUpgradeMessage(userType, language);
      }

      // Check if API key is available
      let apiKey, serviceName;
      if (this.useDeepSeek) {
        apiKey = this.deepseekKey;
        serviceName = 'DeepSeek';
      } else if (this.useGemini) {
        apiKey = this.geminiKey;
        serviceName = 'Gemini';
      } else {
        apiKey = this.openaiKey;
        serviceName = 'OpenAI';
      }
      
      if (!apiKey || apiKey === 'your_deepseek_api_key_here' || apiKey === 'your_gemini_api_key_here' || apiKey === 'your_openai_api_key_here') {
        console.log('No valid API key found, using fallback responses');
        return this.getFallbackResponse(message, language);
      }

      console.log('Using AI service:', serviceName);
      console.log('API Key length:', apiKey.length);
      console.log('üåê Language setting:', language);

      // Prepare prompt based on language
      const systemPrompt = this.getSystemPrompt(language);
      
      // Add Arabic instruction to user message if language is Arabic
      let userMessage = message;
      if (language === 'ar') {
        userMessage = `Please respond in Arabic language only: ${message}`;
        console.log('üåê Arabic mode enabled - Modified user message:', userMessage);
      }
      
      let response;
      
      if (this.useDeepSeek) {
        // Use OpenRouter DeepSeek API
        console.log('Making OpenRouter DeepSeek API request...');
        const deepseekBody = {
          model: 'deepseek/deepseek-chat',
          messages: [
            { role: 'system', content: systemPrompt },
            { role: 'user', content: userMessage }
          ],
          max_tokens: 500,
          temperature: 0.7
        };
        
        console.log('OpenRouter DeepSeek request body:', JSON.stringify(deepseekBody, null, 2));
        
        response = await fetch(this.deepseekURL, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${apiKey}`,
            'HTTP-Referer': 'https://marln-university.com',
            'X-Title': 'MarLn University LMS'
          },
          body: JSON.stringify(deepseekBody)
        });
        
        console.log('OpenRouter DeepSeek response status:', response.status);
      } else if (this.useGemini) {
        // Use Gemini API
        console.log('Making Gemini API request...');
        const geminiBody = {
          contents: [{
            parts: [{
              text: `${systemPrompt}\n\nUser: ${userMessage}`
            }]
          }],
          generationConfig: {
            maxOutputTokens: 500,
            temperature: 0.7,
            topP: 0.8,
            topK: 40
          }
        };
        
        console.log('Gemini request body:', JSON.stringify(geminiBody, null, 2));
        
        response = await fetch(`${this.geminiURL}?key=${apiKey}`, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json'
          },
          body: JSON.stringify(geminiBody)
        });
        
        console.log('Gemini response status:', response.status);
      } else {
        // Use OpenAI API
        console.log('Making OpenAI API request...');
        response = await fetch(this.openaiURL, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${apiKey}`
          },
          body: JSON.stringify({
            model: 'gpt-3.5-turbo',
            messages: [
              { role: 'system', content: systemPrompt },
              { role: 'user', content: userMessage }
            ],
            max_tokens: 500,
            temperature: 0.7
          })
        });
        
        console.log('OpenAI response status:', response.status);
      }

      if (!response.ok) {
        const errorText = await response.text();
        console.error('API Error Response:', errorText);
        console.error('Response Status:', response.status);
        console.error('Response Headers:', response.headers);
        
        // Check if it's a rate limit error (429)
        if (response.status === 429) {
          console.log('üö® API Rate limit hit, showing PRO upgrade message');
          return this.getProUpgradeMessage(userType, language, 'api_rate_limit');
        }
        
        // Check if it's an authentication error (401)
        if (response.status === 401) {
          console.log('üö® API Authentication failed, trying fallback response');
          return this.getFallbackResponse(message, language);
        }
        
        // Try to parse error for better debugging
        try {
          const errorData = JSON.parse(errorText);
          console.error('Parsed Error:', errorData);
        } catch (e) {
          console.error('Raw Error Text:', errorText);
        }
        
        // For other errors, use fallback instead of throwing
        console.log('üö® API Error, using fallback response');
        return this.getFallbackResponse(message, language);
      }

      const data = await response.json();
      console.log('API Response data:', data);
      
      // Extract response based on API
      let aiResponse;
      if (this.useDeepSeek) {
        if (data.choices && data.choices[0] && data.choices[0].message) {
          aiResponse = data.choices[0].message.content;
        } else {
          console.error('Unexpected DeepSeek response structure:', data);
          throw new Error('Invalid DeepSeek response structure');
        }
      } else if (this.useGemini) {
        if (data.candidates && data.candidates[0] && data.candidates[0].content) {
          aiResponse = data.candidates[0].content.parts[0].text;
        } else {
          console.error('Unexpected Gemini response structure:', data);
          throw new Error('Invalid Gemini response structure');
        }
      } else {
        if (data.choices && data.choices[0] && data.choices[0].message) {
          aiResponse = data.choices[0].message.content;
        } else {
          console.error('Unexpected OpenAI response structure:', data);
          throw new Error('Invalid OpenAI response structure');
        }
      }

      console.log('AI Response:', aiResponse);
      console.log('‚úÖ Successfully returning AI response');
      return aiResponse;

    } catch (error) {
      console.error('AI Service Error Details:', error);
      console.error('Error message:', error.message);
      console.error('Error stack:', error.stack);
      
      // Check if it's a network or API error that might benefit from PRO upgrade
      if (error.message.includes('429') || error.message.includes('rate limit') || error.message.includes('too many requests')) {
        console.log('üö® Rate limit error detected, showing PRO upgrade message');
        return this.getProUpgradeMessage(userType, language, 'api_rate_limit');
      }
      
      // For other errors, use fallback
      return this.getFallbackResponse(message, language);
    }
  }

  // Get system prompt based on language
  getSystemPrompt(language) {
    const prompts = {
      en: `You are Sage AI, an intelligent educational assistant for Marln University. 
      Help students with their studies, provide clear explanations, and offer helpful advice. 
      Keep responses concise and educational.`,
      
      ar: `ÿ£ŸÜÿ™ Sage AIÿå ŸÖÿ≥ÿßÿπÿØ ÿ™ÿπŸÑŸäŸÖŸä ÿ∞ŸÉŸä ŸÑÿ¨ÿßŸÖÿπÿ© Marln. 
      ÿ≥ÿßÿπÿØ ÿßŸÑÿ∑ŸÑÿßÿ® ŸÅŸä ÿØÿ±ÿßÿ≥ÿ™ŸáŸÖÿå ŸàŸÇÿØŸÖ ÿ¥ÿ±Ÿàÿ≠ÿßÿ™ Ÿàÿßÿ∂ÿ≠ÿ©ÿå ŸàŸÇÿØŸÖ ŸÜÿµÿßÿ¶ÿ≠ ŸÖŸÅŸäÿØÿ©. 
      ÿßÿ¨ÿπŸÑ ÿßŸÑÿ±ÿØŸàÿØ ŸÖÿÆÿ™ÿµÿ±ÿ© Ÿàÿ™ÿπŸÑŸäŸÖŸäÿ©.
      
      IMPORTANT: You MUST respond in Arabic language only. All your responses should be in Arabic, regardless of the user's input language. Use proper Arabic grammar, vocabulary, and cultural context appropriate for educational settings.`
    };
    
    return prompts[language] || prompts.en;
  }

  // PRO upgrade messages for rate limits and API errors
  getProUpgradeMessage(userType, language = 'en', reason = 'rate_limit') {
    const messages = {
      en: {
        sage_ai_limit: `üöÄ **Sage AI Limit Reached! Upgrade to PRO for unlimited Sage AI chats!**\n\nYou've used all ${this.sageAILimits.free} free Sage AI chats. PRO users get:\n\n‚Ä¢ **${this.sageAILimits.pro} Sage AI chats** (vs ${this.sageAILimits.free})\n‚Ä¢ **Unlimited overall AI requests**\n‚Ä¢ **Priority access** to all AI services\n‚Ä¢ **Advanced features** not available in free tier\n\nüíé **PRO Sage AI Benefits:**\n‚Ä¢ ${this.sageAILimits.pro} Sage AI chats\n‚Ä¢ No Sage AI limits\n‚Ä¢ Priority processing\n‚Ä¢ Advanced educational tools\n\nUpgrade to PRO for unlimited Sage AI access!`,
        
        rate_limit: `üöÄ **Upgrade to PRO for unlimited AI assistance!**\n\nYou've reached the free tier limit (${this.rateLimit.free.requests} messages per hour). Upgrade to PRO to continue chatting with unlimited messages and access advanced features like:\n\n‚Ä¢ **Plagiarism Detection Patterns** - Spot common cheating techniques\n‚Ä¢ **Code Feedback Suggestions** - AI-powered code review assistance\n‚Ä¢ **Rubric Optimization** - Optimize grading criteria and weights\n‚Ä¢ **Student Analytics** - Analyze performance patterns\n‚Ä¢ **Extended Chat Sessions** - Unlimited conversations\n\nüíé **PRO Features:**\n‚Ä¢ Unlimited AI conversations\n‚Ä¢ Advanced educational tools\n‚Ä¢ Priority support\n‚Ä¢ Custom prompt templates\n‚Ä¢ Student performance insights\n\nClick the PRO badge to upgrade now!`,
        
        api_rate_limit: `ü§ñ **AI is currently busy! Upgrade to PRO for priority access!**\n\nOur AI service is experiencing high demand. PRO users get:\n\n‚Ä¢ **Priority access** to AI responses\n‚Ä¢ **Unlimited requests** - no rate limits\n‚Ä¢ **Faster response times**\n‚Ä¢ **Advanced features** not available in free tier\n‚Ä¢ **24/7 priority support**\n\nüíé **PRO Benefits:**\n‚Ä¢ Skip the queue\n‚Ä¢ Unlimited AI conversations\n‚Ä¢ Advanced educational tools\n‚Ä¢ Custom AI models\n‚Ä¢ Student analytics\n\nUpgrade now to never wait for AI responses again!`,
        
        default: `üöÄ **Upgrade to PRO for the best AI experience!**\n\nGet unlimited access to advanced AI features and never worry about limits again.\n\nüíé **PRO Features:**\n‚Ä¢ Unlimited AI conversations\n‚Ä¢ Advanced educational tools\n‚Ä¢ Priority support\n‚Ä¢ Custom prompt templates\n‚Ä¢ Student performance insights`
      },
      ar: {
        rate_limit: `üöÄ **ÿßÿ±ÿ™ŸÇŸê ÿ•ŸÑŸâ PRO ŸÑŸÑÿ≠ÿµŸàŸÑ ÿπŸÑŸâ ŸÖÿ≥ÿßÿπÿØÿ© ÿ∞ŸÉŸäÿ© ÿ∫Ÿäÿ± ŸÖÿ≠ÿØŸàÿØÿ©!**\n\nŸÑŸÇÿØ ŸàÿµŸÑÿ™ ÿ•ŸÑŸâ ÿ≠ÿØ ÿßŸÑÿ∑ÿ®ŸÇÿ© ÿßŸÑŸÖÿ¨ÿßŸÜŸäÿ© (${this.rateLimit.free.requests} ÿ±ÿ≥ÿßŸÑÿ© ŸÅŸä ÿßŸÑÿ≥ÿßÿπÿ©). ÿßÿ±ÿ™ŸÇŸê ÿ•ŸÑŸâ PRO ŸÑŸÑÿßÿ≥ÿ™ŸÖÿ±ÿßÿ± ŸÅŸä ÿßŸÑÿØÿ±ÿØÿ¥ÿ© ŸÖÿπ ÿ±ÿ≥ÿßÿ¶ŸÑ ÿ∫Ÿäÿ± ŸÖÿ≠ÿØŸàÿØÿ© ŸàÿßŸÑŸàÿµŸàŸÑ ÿ•ŸÑŸâ ŸÖŸäÿ≤ÿßÿ™ ŸÖÿ™ŸÇÿØŸÖÿ© ŸÖÿ´ŸÑ:\n\n‚Ä¢ **ÿ£ŸÜŸÖÿßÿ∑ ÿßŸÉÿ™ÿ¥ÿßŸÅ ÿßŸÑÿßŸÜÿ™ÿ≠ÿßŸÑ** - ÿßŸÉÿ™ÿ¥ŸÅ ÿ™ŸÇŸÜŸäÿßÿ™ ÿßŸÑÿ∫ÿ¥ ÿßŸÑÿ¥ÿßÿ¶ÿπÿ©\n‚Ä¢ **ÿßŸÇÿ™ÿ±ÿßÿ≠ÿßÿ™ ŸÖÿ±ÿßÿ¨ÿπÿ© ÿßŸÑŸÉŸàÿØ** - ŸÖÿ≥ÿßÿπÿØÿ© ŸÖÿ±ÿßÿ¨ÿπÿ© ÿßŸÑŸÉŸàÿØ ÿ®ÿßŸÑÿ∞ŸÉÿßÿ° ÿßŸÑÿßÿµÿ∑ŸÜÿßÿπŸä\n‚Ä¢ **ÿ™ÿ≠ÿ≥ŸäŸÜ ÿßŸÑŸÖÿπÿßŸäŸäÿ±** - ÿ™ÿ≠ÿ≥ŸäŸÜ ŸÖÿπÿßŸäŸäÿ± ÿßŸÑÿ™ŸÇŸäŸäŸÖ ŸàÿßŸÑÿ£Ÿàÿ≤ÿßŸÜ\n‚Ä¢ **ÿ™ÿ≠ŸÑŸäŸÑÿßÿ™ ÿßŸÑÿ∑ŸÑÿßÿ®** - ÿ™ÿ≠ŸÑŸäŸÑ ÿ£ŸÜŸÖÿßÿ∑ ÿßŸÑÿ£ÿØÿßÿ°\n‚Ä¢ **ÿ¨ŸÑÿ≥ÿßÿ™ ÿØÿ±ÿØÿ¥ÿ© ŸÖŸÖÿ™ÿØÿ©** - ŸÖÿ≠ÿßÿØÿ´ÿßÿ™ ÿ∫Ÿäÿ± ŸÖÿ≠ÿØŸàÿØÿ©\n\nüíé **ŸÖŸäÿ≤ÿßÿ™ PRO:**\n‚Ä¢ ŸÖÿ≠ÿßÿØÿ´ÿßÿ™ ÿ∞ŸÉŸäÿ© ÿ∫Ÿäÿ± ŸÖÿ≠ÿØŸàÿØÿ©\n‚Ä¢ ÿ£ÿØŸàÿßÿ™ ÿ™ÿπŸÑŸäŸÖŸäÿ© ŸÖÿ™ŸÇÿØŸÖÿ©\n‚Ä¢ ÿØÿπŸÖ ÿ∞Ÿà ÿ£ŸàŸÑŸàŸäÿ©\n‚Ä¢ ŸÇŸàÿßŸÑÿ® ÿ™Ÿàÿ¨ŸäŸá ŸÖÿÆÿµÿµÿ©\n‚Ä¢ ÿ±ÿ§Ÿâ ÿ£ÿØÿßÿ° ÿßŸÑÿ∑ŸÑÿßÿ®\n\nÿßŸÜŸÇÿ± ÿπŸÑŸâ ÿ¥ÿßÿ±ÿ© PRO ŸÑŸÑÿ™ÿ±ŸÇŸäÿ© ÿßŸÑÿ¢ŸÜ!`,
        
        api_rate_limit: `ü§ñ **ÿßŸÑÿ∞ŸÉÿßÿ° ÿßŸÑÿßÿµÿ∑ŸÜÿßÿπŸä ŸÖÿ¥ÿ∫ŸàŸÑ ÿ≠ÿßŸÑŸäÿßŸã! ÿßÿ±ÿ™ŸÇŸê ÿ•ŸÑŸâ PRO ŸÑŸÑŸàÿµŸàŸÑ ÿ∞Ÿà ÿßŸÑÿ£ŸàŸÑŸàŸäÿ©!**\n\nÿÆÿØŸÖÿ© ÿßŸÑÿ∞ŸÉÿßÿ° ÿßŸÑÿßÿµÿ∑ŸÜÿßÿπŸä ŸÑÿØŸäŸÜÿß ÿ™ÿπÿßŸÜŸä ŸÖŸÜ ÿ∑ŸÑÿ® ŸÖÿ±ÿ™ŸÅÿπ. ŸÖÿ≥ÿ™ÿÆÿØŸÖŸà PRO Ÿäÿ≠ÿµŸÑŸàŸÜ ÿπŸÑŸâ:\n\n‚Ä¢ **ŸàÿµŸàŸÑ ÿ∞Ÿà ÿ£ŸàŸÑŸàŸäÿ©** ŸÑŸÑÿ±ÿØŸàÿØ ÿßŸÑÿ∞ŸÉŸäÿ©\n‚Ä¢ **ÿ∑ŸÑÿ®ÿßÿ™ ÿ∫Ÿäÿ± ŸÖÿ≠ÿØŸàÿØÿ©** - ÿ®ÿØŸàŸÜ ÿ≠ÿØŸàÿØ ŸÖÿπÿØŸÑ\n‚Ä¢ **ÿ£ŸàŸÇÿßÿ™ ÿßÿ≥ÿ™ÿ¨ÿßÿ®ÿ© ÿ£ÿ≥ÿ±ÿπ**\n‚Ä¢ **ŸÖŸäÿ≤ÿßÿ™ ŸÖÿ™ŸÇÿØŸÖÿ©** ÿ∫Ÿäÿ± ŸÖÿ™ŸàŸÅÿ±ÿ© ŸÅŸä ÿßŸÑÿ∑ÿ®ŸÇÿ© ÿßŸÑŸÖÿ¨ÿßŸÜŸäÿ©\n‚Ä¢ **ÿØÿπŸÖ ÿ∞Ÿà ÿ£ŸàŸÑŸàŸäÿ© ÿπŸÑŸâ ŸÖÿØÿßÿ± ÿßŸÑÿ≥ÿßÿπÿ©**\n\nüíé **ŸÅŸàÿßÿ¶ÿØ PRO:**\n‚Ä¢ ÿ™ÿÆÿ∑Ÿä ÿßŸÑÿ∑ÿßÿ®Ÿàÿ±\n‚Ä¢ ŸÖÿ≠ÿßÿØÿ´ÿßÿ™ ÿ∞ŸÉŸäÿ© ÿ∫Ÿäÿ± ŸÖÿ≠ÿØŸàÿØÿ©\n‚Ä¢ ÿ£ÿØŸàÿßÿ™ ÿ™ÿπŸÑŸäŸÖŸäÿ© ŸÖÿ™ŸÇÿØŸÖÿ©\n‚Ä¢ ŸÜŸÖÿßÿ∞ÿ¨ ÿ∞ŸÉŸäÿ© ŸÖÿÆÿµÿµÿ©\n‚Ä¢ ÿ™ÿ≠ŸÑŸäŸÑÿßÿ™ ÿßŸÑÿ∑ŸÑÿßÿ®\n\nÿßÿ±ÿ™ŸÇŸê ÿßŸÑÿ¢ŸÜ ŸÑÿπÿØŸÖ ÿßŸÑÿßŸÜÿ™ÿ∏ÿßÿ± ŸÑÿ±ÿØŸàÿØ ÿßŸÑÿ∞ŸÉÿßÿ° ÿßŸÑÿßÿµÿ∑ŸÜÿßÿπŸä ŸÖÿ±ÿ© ÿ£ÿÆÿ±Ÿâ!`,
        
        default: `üöÄ **ÿßÿ±ÿ™ŸÇŸê ÿ•ŸÑŸâ PRO ŸÑÿ£ŸÅÿ∂ŸÑ ÿ™ÿ¨ÿ±ÿ®ÿ© ÿ∞ŸÉŸäÿ©!**\n\nÿßÿ≠ÿµŸÑ ÿπŸÑŸâ ŸàÿµŸàŸÑ ÿ∫Ÿäÿ± ŸÖÿ≠ÿØŸàÿØ ŸÑŸÑŸÖŸäÿ≤ÿßÿ™ ÿßŸÑÿ∞ŸÉŸäÿ© ÿßŸÑŸÖÿ™ŸÇÿØŸÖÿ© ŸàŸÑÿß ÿ™ŸÇŸÑŸÇ ÿ®ÿ¥ÿ£ŸÜ ÿßŸÑÿ≠ÿØŸàÿØ ŸÖÿ±ÿ© ÿ£ÿÆÿ±Ÿâ.\n\nüíé **ŸÖŸäÿ≤ÿßÿ™ PRO:**\n‚Ä¢ ŸÖÿ≠ÿßÿØÿ´ÿßÿ™ ÿ∞ŸÉŸäÿ© ÿ∫Ÿäÿ± ŸÖÿ≠ÿØŸàÿØÿ©\n‚Ä¢ ÿ£ÿØŸàÿßÿ™ ÿ™ÿπŸÑŸäŸÖŸäÿ© ŸÖÿ™ŸÇÿØŸÖÿ©\n‚Ä¢ ÿØÿπŸÖ ÿ∞Ÿà ÿ£ŸàŸÑŸàŸäÿ©\n‚Ä¢ ŸÇŸàÿßŸÑÿ® ÿ™Ÿàÿ¨ŸäŸá ŸÖÿÆÿµÿµÿ©\n‚Ä¢ ÿ±ÿ§Ÿâ ÿ£ÿØÿßÿ° ÿßŸÑÿ∑ŸÑÿßÿ®`
      }
    };

    const langMessages = messages[language] || messages.en;
    return langMessages[reason] || langMessages.default;
  }

  // Fallback responses when AI is not available
  getFallbackResponse(message, language = 'en') {
    const fallbackResponses = {
      en: [
        "I'm here to help with your studies! What specific topic would you like to discuss?",
        "That's an interesting question. Let me help you understand this better.",
        "I can assist you with course materials, study tips, and academic guidance.",
        "Feel free to ask me about any subject you're studying. I'm here to help!",
        "Great question! Let's explore this topic together.",
        "I'm currently in demo mode. I can help you with study strategies, course materials, and academic guidance. What would you like to know?",
        "Welcome to Sage AI! I'm here to support your learning journey. What topic are you working on today?",
        "I can help you with note-taking techniques, exam preparation, and understanding complex concepts. What do you need help with?"
      ],
      ar: [
        "ÿ£ŸÜÿß ŸáŸÜÿß ŸÑŸÖÿ≥ÿßÿπÿØÿ™ŸÉ ŸÅŸä ÿØÿ±ÿßÿ≥ÿ™ŸÉ! ŸÖÿß ŸáŸà ÿßŸÑŸÖŸàÿ∂Ÿàÿπ ÿßŸÑŸÖÿ≠ÿØÿØ ÿßŸÑÿ∞Ÿä ÿ™ÿ±ŸäÿØ ŸÖŸÜÿßŸÇÿ¥ÿ™Ÿáÿü",
        "Ÿáÿ∞ÿß ÿ≥ÿ§ÿßŸÑ ŸÖÿ´Ÿäÿ± ŸÑŸÑÿßŸáÿ™ŸÖÿßŸÖ. ÿØÿπŸÜŸä ÿ£ÿ≥ÿßÿπÿØŸÉ ŸÅŸä ŸÅŸáŸÖ Ÿáÿ∞ÿß ÿ®ÿ¥ŸÉŸÑ ÿ£ŸÅÿ∂ŸÑ.",
        "ŸäŸÖŸÉŸÜŸÜŸä ŸÖÿ≥ÿßÿπÿØÿ™ŸÉ ŸÅŸä ÿßŸÑŸÖŸàÿßÿØ ÿßŸÑÿØÿ±ÿßÿ≥Ÿäÿ© ŸàŸÜÿµÿßÿ¶ÿ≠ ÿßŸÑÿØÿ±ÿßÿ≥ÿ© ŸàÿßŸÑÿ™Ÿàÿ¨ŸäŸá ÿßŸÑÿ£ŸÉÿßÿØŸäŸÖŸä.",
        "ŸÑÿß ÿ™ÿ™ÿ±ÿØÿØ ŸÅŸä ÿ≥ÿ§ÿßŸÑŸä ÿπŸÜ ÿ£Ÿä ŸÖÿßÿØÿ© ÿ™ÿØÿ±ÿ≥Ÿáÿß. ÿ£ŸÜÿß ŸáŸÜÿß ŸÑŸÑŸÖÿ≥ÿßÿπÿØÿ©!",
        "ÿ≥ÿ§ÿßŸÑ ÿ±ÿßÿ¶ÿπ! ÿØÿπŸÜÿß ŸÜÿ≥ÿ™ŸÉÿ¥ŸÅ Ÿáÿ∞ÿß ÿßŸÑŸÖŸàÿ∂Ÿàÿπ ŸÖÿπÿßŸã.",
        "ÿ£ŸÜÿß ÿ≠ÿßŸÑŸäÿßŸã ŸÅŸä ÿßŸÑŸàÿ∂ÿπ ÿßŸÑÿ™ÿ¨ÿ±Ÿäÿ®Ÿä. ŸäŸÖŸÉŸÜŸÜŸä ŸÖÿ≥ÿßÿπÿØÿ™ŸÉ ŸÅŸä ÿßÿ≥ÿ™ÿ±ÿßÿ™Ÿäÿ¨Ÿäÿßÿ™ ÿßŸÑÿØÿ±ÿßÿ≥ÿ© ŸàÿßŸÑŸÖŸàÿßÿØ ÿßŸÑÿØÿ±ÿßÿ≥Ÿäÿ© ŸàÿßŸÑÿ™Ÿàÿ¨ŸäŸá ÿßŸÑÿ£ŸÉÿßÿØŸäŸÖŸä. ŸÖÿßÿ∞ÿß ÿ™ÿ±ŸäÿØ ÿ£ŸÜ ÿ™ÿπÿ±ŸÅÿü",
        "ŸÖÿ±ÿ≠ÿ®ÿßŸã ÿ®ŸÉ ŸÅŸä Sage AI! ÿ£ŸÜÿß ŸáŸÜÿß ŸÑÿØÿπŸÖ ÿ±ÿ≠ŸÑÿ© ÿ™ÿπŸÑŸÖŸÉ. ŸÖÿß ŸáŸà ÿßŸÑŸÖŸàÿ∂Ÿàÿπ ÿßŸÑÿ∞Ÿä ÿ™ÿπŸÖŸÑ ÿπŸÑŸäŸá ÿßŸÑŸäŸàŸÖÿü",
        "ŸäŸÖŸÉŸÜŸÜŸä ŸÖÿ≥ÿßÿπÿØÿ™ŸÉ ŸÅŸä ÿ™ŸÇŸÜŸäÿßÿ™ ÿ™ÿØŸàŸäŸÜ ÿßŸÑŸÖŸÑÿßÿ≠ÿ∏ÿßÿ™ ŸàÿßŸÑÿ™ÿ≠ÿ∂Ÿäÿ± ŸÑŸÑÿßŸÖÿ™ÿ≠ÿßŸÜÿßÿ™ ŸàŸÅŸáŸÖ ÿßŸÑŸÖŸÅÿßŸáŸäŸÖ ÿßŸÑŸÖÿπŸÇÿØÿ©. ŸÅŸäŸÖ ÿ™ÿ≠ÿ™ÿßÿ¨ ÿßŸÑŸÖÿ≥ÿßÿπÿØÿ©ÿü"
      ]
    };

    const responses = fallbackResponses[language] || fallbackResponses.en;
    return responses[Math.floor(Math.random() * responses.length)];
  }

  // Get remaining requests for user
  getRemainingRequests(userId, userType = 'free') {
    const now = Date.now();
    const limit = this.rateLimit[userType];
    
    if (!this.userRequests.has(userId)) {
      return limit.requests;
    }
    
    const userRequests = this.userRequests.get(userId);
    const recentRequests = userRequests.filter(time => now - time < limit.window);
    
    return Math.max(0, limit.requests - recentRequests.length);
  }

  // Reset rate limit for testing
  resetRateLimit(userId) {
    this.userRequests.delete(userId);
    console.log(`Rate limit reset for user: ${userId}`);
  }

  // Reset all rate limits (for testing)
  resetAllRateLimits() {
    this.userRequests.clear();
    this.sageAIRequests.clear();
    // Also clear from localStorage
    try {
      localStorage.removeItem('sageAIRequests');
      console.log('üóëÔ∏è All rate limits reset and cleared from localStorage');
    } catch (error) {
      console.warn('‚ö†Ô∏è Failed to clear Sage AI requests from localStorage:', error);
    }
  }

  // Reset Sage AI limits specifically
  resetSageAILimits() {
    this.sageAIRequests.clear();
    // Also clear from localStorage
    try {
      localStorage.removeItem('sageAIRequests');
      console.log('üóëÔ∏è Sage AI limits reset and cleared from localStorage');
    } catch (error) {
      console.warn('‚ö†Ô∏è Failed to clear Sage AI requests from localStorage:', error);
    }
  }

  // Debug function to test Sage AI response
  async testSageAIResponse(message = 'Hello, can you help me with my studies?') {
    console.log('üß™ Testing Sage AI response...');
    console.log('  - Message:', message);
    
    try {
      const response = await this.getAIResponse(message, 'test-user', 'free', 'en', true);
      console.log('‚úÖ Test response:', response);
      return response;
    } catch (error) {
      console.error('‚ùå Test failed:', error);
      return null;
    }
  }

  // Check API key status and provide guidance
  checkAPIKeyStatus() {
    console.log('üîç API Key Status Check:');
    
    const status = {
      openai: {
        hasKey: !!this.openaiKey && this.openaiKey.length > 0,
        keyLength: this.openaiKey.length,
        isDefault: this.openaiKey === 'your_openai_api_key_here'
      },
      gemini: {
        hasKey: !!this.geminiKey && this.geminiKey.length > 0,
        keyLength: this.geminiKey.length,
        isDefault: this.geminiKey === 'your_gemini_api_key_here'
      },
      deepseek: {
        hasKey: !!this.deepseekKey && this.deepseekKey.length > 0,
        keyLength: this.deepseekKey.length,
        isDefault: this.deepseekKey === 'your_deepseek_api_key_here'
      },
      currentService: this.useDeepSeek ? 'DeepSeek' : (this.useGemini ? 'Gemini' : 'OpenAI')
    };
    
    console.log('üìä Status:', status);
    
    if (status.currentService === 'DeepSeek' && !status.deepseek.hasKey) {
      console.log('‚ö†Ô∏è DeepSeek is selected but no API key found!');
      console.log('üí° To fix: Add VITE_DEEPSEEK_API_KEY to your .env file');
    } else if (status.currentService === 'Gemini' && !status.gemini.hasKey) {
      console.log('‚ö†Ô∏è Gemini is selected but no API key found!');
      console.log('üí° To fix: Add VITE_GEMINI_API_KEY to your .env file');
    } else if (status.currentService === 'OpenAI' && !status.openai.hasKey) {
      console.log('‚ö†Ô∏è OpenAI is selected but no API key found!');
      console.log('üí° To fix: Add VITE_OPENAI_API_KEY to your .env file');
    }
    
    return status;
  }

  // Get current rate limit status
  getRateLimitStatus(userId, userType = 'free') {
    const remaining = this.getRemainingRequests(userId, userType);
    const limit = this.rateLimit[userType];
    return {
      remaining,
      total: limit.requests,
      window: limit.window,
      isLimited: remaining === 0
    };
  }

  // Test function to check API connection
  async testConnection() {
    console.log('üß™ Starting API connection test...');
    try {
      let apiKey, serviceName;
      if (this.useDeepSeek) {
        apiKey = this.deepseekKey;
        serviceName = 'DeepSeek';
      } else if (this.useGemini) {
        apiKey = this.geminiKey;
        serviceName = 'Gemini';
      } else {
        apiKey = this.openaiKey;
        serviceName = 'OpenAI';
      }
      
      if (!apiKey || apiKey === 'your_deepseek_api_key_here' || apiKey === 'your_gemini_api_key_here' || apiKey === 'your_openai_api_key_here') {
        return { success: false, error: 'No valid API key found' };
      }

      console.log('Testing API connection...');
      console.log('Using service:', serviceName);
      console.log('API Key length:', apiKey.length);

      if (this.useDeepSeek) {
        // OpenRouter DeepSeek test
        const response = await fetch(this.deepseekURL, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${apiKey}`,
            'HTTP-Referer': 'https://marln-university.com',
            'X-Title': 'MarLn University LMS'
          },
          body: JSON.stringify({
            model: 'deepseek/deepseek-chat',
            messages: [
              { role: 'user', content: "Hello, this is a test message. Please respond with 'Test successful'." }
            ],
            max_tokens: 50
          })
        });

        if (response.ok) {
          const data = await response.json();
          return { success: true, data };
        } else {
          const errorText = await response.text();
          return { success: false, error: `HTTP ${response.status}: ${errorText}` };
        }
      } else if (this.useGemini) {
        const testBody = {
          contents: [{
            parts: [{
              text: "Hello, this is a test message. Please respond with 'Test successful'."
            }]
          }],
          generationConfig: {
            maxOutputTokens: 50,
            temperature: 0.1
          }
        };

        const response = await fetch(`${this.geminiURL}?key=${apiKey}`, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json'
          },
          body: JSON.stringify(testBody)
        });

        if (response.ok) {
          const data = await response.json();
          return { success: true, data };
        } else {
          const errorText = await response.text();
          return { success: false, error: `HTTP ${response.status}: ${errorText}` };
        }
      } else {
        // OpenAI test
        const response = await fetch(this.openaiURL, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${apiKey}`
          },
          body: JSON.stringify({
            model: 'gpt-3.5-turbo',
            messages: [
              { role: 'user', content: "Hello, this is a test message. Please respond with 'Test successful'." }
            ],
            max_tokens: 50
          })
        });

        if (response.ok) {
          const data = await response.json();
          return { success: true, data };
        } else {
          const errorText = await response.text();
          return { success: false, error: `HTTP ${response.status}: ${errorText}` };
        }
      }
    } catch (error) {
      return { success: false, error: error.message };
    }
  }
}

// Create singleton instance
const aiService = new AIService();

export default aiService; 